# Customer_Churn_Prediction

# Telco Customer Churn Prediction

This project predicts customer churn for a telecommunications company using a logistic regression model with a minimal feature set. It includes a Jupyter Notebook for model training and a Streamlit app for interactive predictions.

## Features
- **Model**: Logistic regression trained on 6 key features: `tenure`, `MonthlyCharges`, `Contract_One year`, `Contract_Two year`, `InternetService_Fiber optic`, `InternetService_No`.
- **App**: A Streamlit web app for single or batch predictions via manual input or CSV upload.
- **Dataset**: Uses the Telco Customer Churn dataset (not included; available from [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)).

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/telco-churn-prediction.git
   cd telco-churn-prediction
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Download the dataset (`WA_Fn-UseC_-Telco-Customer-Churn.csv`) from Kaggle and place it in the project directory.

## Usage
1. **Train the Model**:
   - Open `LogisticRegression.ipynb` in Jupyter Notebook.
   - Run all cells to generate `recall_logreg.pkl`, `scaler.pkl`, and `encoder.pkl`.
2. **Run the Streamlit App**:
   - Run:
     ```bash
     streamlit run app.py
     ```
   - Access the app in your browser (typically `http://localhost:8501`).
   - Use the form for single predictions or upload `test_data.csv` for batch predictions.
3. **Test with Sample Data**:
   - Use `test_data.csv` for batch predictions:
     ```csv
     customerID,tenure,MonthlyCharges,Contract,InternetService
     CUST001,12,70.5,Month-to-month,Fiber optic
     CUST002,48,45.0,Two year,DSL
     ...
     ```
   - Try manual inputs, e.g., `tenure=3`, `MonthlyCharges=95.0`, `Contract=Month-to-month`, `InternetService=Fiber optic` (expected: churn).

## Files
- `LogisticRegression.ipynb`: Trains the model and saves artifacts.
- `app.py`: Streamlit app for predictions.
- `test_data.csv`: Sample data for testing.
- `requirements.txt`: Python dependencies.
- `recall_logreg.pkl`, `scaler.pkl`, `encoder.pkl`: Model and preprocessing files (generated by notebook).

## Notes
- The dataset is not included due to size and licensing. Download it from Kaggle.
- The model uses a minimal feature set for simplicity. Accuracy may be slightly lower than using all features.
- Ensure `scikit-learn` and `pandas` versions match between training and app environments.

## License
MIT License
